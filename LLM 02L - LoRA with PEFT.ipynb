{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87482f99-0b05-41f2-ab65-7503e22dc0fc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n",
    "  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b9ba9df-5a9b-4020-a131-5db37c8f9922",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Low-Rank Adaption (LoRA)\n",
    "This lab introduces how to apply low-rank adaptation (LoRA) to your model of choice using [Parameter-Efficient Fine-Tuning (PEFT) library developed by Hugging Face](https://huggingface.co/docs/peft/index). \n",
    "\n",
    "\n",
    "### ![Dolly](https://files.training.databricks.com/images/llm/dolly_small.png) Learning Objectives\n",
    "1. Apply LoRA to a model\n",
    "1. Fine-tune on your provided dataset\n",
    "1. Save your model\n",
    "1. Conduct inference using the fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63fc1c67-e848-41c4-bf6d-45edaf54a99a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nCollecting peft==0.4.0\n  Downloading peft-0.4.0-py3-none-any.whl (72 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 72.9/72.9 kB 1.8 MB/s eta 0:00:00\nRequirement already satisfied: torch>=1.13.0 in /databricks/python3/lib/python3.10/site-packages (from peft==0.4.0) (1.13.1+cpu)\nRequirement already satisfied: psutil in /databricks/python3/lib/python3.10/site-packages (from peft==0.4.0) (5.9.0)\nRequirement already satisfied: pyyaml in /databricks/python3/lib/python3.10/site-packages (from peft==0.4.0) (6.0)\nRequirement already satisfied: numpy>=1.17 in /databricks/python3/lib/python3.10/site-packages (from peft==0.4.0) (1.21.5)\nRequirement already satisfied: packaging>=20.0 in /databricks/python3/lib/python3.10/site-packages (from peft==0.4.0) (21.3)\nRequirement already satisfied: accelerate in /databricks/python3/lib/python3.10/site-packages (from peft==0.4.0) (0.19.0)\nCollecting safetensors\n  Downloading safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 8.6 MB/s eta 0:00:00\nRequirement already satisfied: transformers in /databricks/python3/lib/python3.10/site-packages (from peft==0.4.0) (4.29.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /databricks/python3/lib/python3.10/site-packages (from packaging>=20.0->peft==0.4.0) (3.0.9)\nRequirement already satisfied: typing-extensions in /databricks/python3/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.4.0) (4.3.0)\nRequirement already satisfied: regex!=2019.12.17 in /databricks/python3/lib/python3.10/site-packages (from transformers->peft==0.4.0) (2022.7.9)\nRequirement already satisfied: filelock in /databricks/python3/lib/python3.10/site-packages (from transformers->peft==0.4.0) (3.6.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /databricks/python3/lib/python3.10/site-packages (from transformers->peft==0.4.0) (0.15.1)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /databricks/python3/lib/python3.10/site-packages (from transformers->peft==0.4.0) (0.13.3)\nRequirement already satisfied: tqdm>=4.27 in /databricks/python3/lib/python3.10/site-packages (from transformers->peft==0.4.0) (4.64.1)\nRequirement already satisfied: requests in /databricks/python3/lib/python3.10/site-packages (from transformers->peft==0.4.0) (2.28.1)\nRequirement already satisfied: fsspec in /databricks/python3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers->peft==0.4.0) (2022.7.1)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.10/site-packages (from requests->transformers->peft==0.4.0) (3.3)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /databricks/python3/lib/python3.10/site-packages (from requests->transformers->peft==0.4.0) (1.26.11)\nRequirement already satisfied: charset-normalizer<3,>=2 in /databricks/python3/lib/python3.10/site-packages (from requests->transformers->peft==0.4.0) (2.0.4)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.10/site-packages (from requests->transformers->peft==0.4.0) (2022.9.14)\nInstalling collected packages: safetensors, peft\nSuccessfully installed peft-0.4.0 safetensors-0.4.2\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install peft==0.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eda23989-89cc-4bf1-8f2c-08614536e71d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resetting the learning environment:\n| enumerating serving endpoints...found 5...(0 seconds)\n| removing the working directory \"dbfs:/mnt/dbacademy-users/labuser5526367@vocareum.com/llm-foundation-models\"...(1 seconds)\n\nSkipping install of existing datasets to \"dbfs:/mnt/dbacademy-datasets/llm-foundation-models/v01-raw\"\n\nValidating the locally installed datasets:\n| listing local files...(3 seconds)\n| removing extra file: /datasets/Abirate___json/Abirate--english_quotes-6e72855d06356857/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-768c685e1cb83483.arrow...(0 seconds)\n| removing extra file: /datasets/_dbfs_mnt_dbacademy-datasets_llm-foundation-models_v01-raw_datasets_Abirate___json_Abirate--english_quotes-6e72855d06356857_0.0.0_e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4.lock...(0 seconds)\n| fixed 2 issues...(3 seconds total)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing lab testing framework.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nUsing the \"default\" schema.\n\nPredefined paths variables:\n| DA.paths.working_dir: /dbfs/mnt/dbacademy-users/labuser5526367@vocareum.com/llm-foundation-models\n| DA.paths.user_db:     dbfs:/mnt/dbacademy-users/labuser5526367@vocareum.com/llm-foundation-models/database.db\n| DA.paths.datasets:    /dbfs/mnt/dbacademy-datasets/llm-foundation-models/v01-raw\n\nSetup completed (15 seconds)\n\nThe models developed or used in this course are for demonstration and learning purposes only.\nModels may occasionally output offensive, inaccurate, biased information, or harmful instructions.\n"
     ]
    }
   ],
   "source": [
    "%run ../Includes/Classroom-Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "37afc2ff-ce1c-424e-a024-70bf364bf3ab",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "We will re-use the same dataset and model from the demo notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a5178b5-06f9-4ae4-94b6-689fa00b5681",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e885e760e2844b9b5a5ffc45861aa10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/222 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35038b3bc0814c84889f69fb12b71c54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/14.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f4bb0ab3a1541cfbd8abcb540530ce9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/85.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "410529a468c345c6a776bbc949126adb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/715 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72d405efb80e4b228aefcecd3f3f5d66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python_shell/dbruntime/huggingface_patches/datasets.py:13: UserWarning: During large dataset downloads, there could be multiple progress bar widgets that can cause performance issues for your notebook or browser. To avoid these issues, use `datasets.utils.logging.disable_progress_bar()` to turn off the progress bars.\n  warnings.warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9795bc3aa8c4e4daef17ba1c2f34f35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/5.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/dbfs/mnt/dbacademy-datasets/llm-foundation-models/v01-raw/datasets/Abirate___json/Abirate--english_quotes-6e72855d06356857/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7271a5c3338d42ecb40ff5fa85b0eb5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fab788fd5fba47d698f31b1824b3423a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2508 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['quote', 'author', 'tags', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 50\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_name = \"bigscience/bloomz-560m\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "foundation_model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "data = load_dataset(\"Abirate/english_quotes\", cache_dir=DA.paths.datasets+\"/datasets\")\n",
    "data = data.map(lambda samples: tokenizer(samples[\"quote\"]), batched=True)\n",
    "train_sample = data[\"train\"].select(range(50))\n",
    "display(train_sample) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e430e4b8-33a3-4a84-a650-64ec1264825e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Define LoRA configurations\n",
    "\n",
    "By using LoRA, you are unfreezing the attention `Weight_delta` matrix and only updating `W_a` and `W_b`. \n",
    "\n",
    "<img src=\"https://files.training.databricks.com/images/llm/lora.png\" width=300>\n",
    "\n",
    "You can treat `r` (rank) as a hyperparameter. Recall from the lecture that, LoRA can perform well with very small ranks based on [Hu et a 2021's paper](https://arxiv.org/abs/2106.09685). GPT-3's validation accuracies across tasks with ranks from 1 to 64 are quite similar. From [PyTorch Lightning's documentation](https://lightning.ai/pages/community/article/lora-llm/):\n",
    "\n",
    "> A smaller r leads to a simpler low-rank matrix, which results in fewer parameters to learn during adaptation. This can lead to faster training and potentially reduced computational requirements. However, with a smaller r, the capacity of the low-rank matrix to capture task-specific information decreases. This may result in lower adaptation quality, and the model might not perform as well on the new task compared to a higher r.\n",
    "\n",
    "Other arguments:\n",
    "- `lora_dropout`: \n",
    "  - Dropout is a regularization method that reduces overfitting by randomly and temporarily removing nodes during training. \n",
    "  - It works like this: <br>\n",
    "    * Apply to most type of layers (e.g. fully connected, convolutional, recurrent) and larger networks\n",
    "    * Temporarily and randomly remove nodes and their connections during each training cycle\n",
    "    ![](https://files.training.databricks.com/images/nn_dropout.png)\n",
    "    * See the original paper here: <a href=\"http://jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf\" target=\"_blank\">Dropout: A Simple Way to Prevent Neural Networks from Overfitting</a>\n",
    "- `target_modules`:\n",
    "  - Specifies the module names to apply to \n",
    "  - This is dependent on how the foundation model names its attention weight matrices. \n",
    "  - Typically, this can be:\n",
    "    - `query`, `q`, `q_proj` \n",
    "    - `key`, `k`, `k_proj` \n",
    "    - `value`, `v` , `v_proj` \n",
    "    - `query_key_value` \n",
    "  - The easiest way to inspect the module/layer names is to print the model, like we are doing below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e406a354-4671-4ad0-bf7b-aa1899171665",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Question 1\n",
    "\n",
    "Fill in `r=1` and `target_modules`. \n",
    "\n",
    "Note:\n",
    "- For `r`, any number is valid. The smaller the r is, the fewer parameters there are to update during the fine-tuning process.\n",
    "\n",
    "Hint: \n",
    "- For `target_modules`, what's the name of the **first** module within each `BloomBlock`'s `self_attention`? \n",
    "\n",
    "Read more about [`LoraConfig` here](https://huggingface.co/docs/peft/conceptual_guides/lora#common-lora-parameters-in-peft)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0984c8a5-4c16-4ac3-a596-24ff056f3865",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "import peft\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=1,\n",
    "    lora_alpha=1, # a scaling factor that adjusts the magnitude of the weight matrix. Usually set to 1\n",
    "    target_modules=[\"query_key_value\"],\n",
    "    lora_dropout=0.05, \n",
    "    bias=\"none\", # this specifies if the bias parameter should be trained. \n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5aa3d83e-5f38-4375-8235-a4eae322aea5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32mPASSED\u001B[0m: All tests passed for lesson2, question1\n\u001B[32mRESULTS RECORDED\u001B[0m: Click `Submit` when all questions are completed to log the results.\n"
     ]
    }
   ],
   "source": [
    "# Test your answer. DO NOT MODIFY THIS CELL.\n",
    "\n",
    "dbTestQuestion2_1(lora_config.r, lora_config.target_modules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "852b603f-8022-47cf-a245-71a3238945c8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "###  Question 2\n",
    "\n",
    "Add the adapter layers to the foundation model to be trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "391dc53f-56ee-44be-ba9a-aef8f87977ec",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 98,304 || all params: 559,312,896 || trainable%: 0.01757585078102687\nNone\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "peft_model = get_peft_model(foundation_model, lora_config)\n",
    "print(peft_model.print_trainable_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e4eb585-ebc2-4c01-8b30-0cfcadd64e13",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32mPASSED\u001B[0m: All tests passed for lesson2, question2\n\u001B[32mRESULTS RECORDED\u001B[0m: Click `Submit` when all questions are completed to log the results.\n"
     ]
    }
   ],
   "source": [
    "# Test your answer. DO NOT MODIFY THIS CELL.\n",
    "\n",
    "dbTestQuestion2_2(peft_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6212cab1-763f-4ad9-abfe-5cee34a99ed1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Define `Trainer` class for fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e4083a0-8c0d-4652-9946-a40ea817ed16",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Question 3 \n",
    "\n",
    "Fill out the `Trainer` class. Feel free to tweak the `training_args` we provided, but remember that lowering the learning rate and increasing the number of epochs will increase training time significantly. If you change none of the defaults we set below, it could take ~15 mins to fine-tune."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b25fabc1-21d6-44c9-97fb-50879cdd21cf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.10/site-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\nYou're using a BloomTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='35' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 12:38, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TrainOutput(global_step=35, training_loss=6.741991751534599, metrics={'train_runtime': 764.9502, 'train_samples_per_second': 0.327, 'train_steps_per_second': 0.046, 'total_flos': 58346118414336.0, 'train_loss': 6.741991751534599, 'epoch': 5.0})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "import transformers\n",
    "from transformers import TrainingArguments, Trainer\n",
    "import os\n",
    "import mlflow\n",
    "\n",
    "# Tell MLflow Tracking to use this explicit experiment path,\n",
    "# which is located on the left hand sidebar under Machine Learning -> Experiments \n",
    "mlflow.set_experiment(f\"/Users/{DA.username}/LLM 02L - LoRA with PEFT\")\n",
    "\n",
    "output_directory = os.path.join(DA.paths.working_dir, \"peft_lab_outputs\")\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_directory,\n",
    "    auto_find_batch_size=True,\n",
    "    learning_rate= 3e-2, # Higher learning rate than full fine-tuning.\n",
    "    num_train_epochs=5,\n",
    "    no_cuda=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=foundation_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_sample,\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "563ba473-ec2b-4323-b55a-5ae9fd63f579",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32mPASSED\u001B[0m: All tests passed for lesson2, question3\n\u001B[32mRESULTS RECORDED\u001B[0m: Click `Submit` when all questions are completed to log the results.\n"
     ]
    }
   ],
   "source": [
    "# Test your answer. DO NOT MODIFY THIS CELL.\n",
    "\n",
    "dbTestQuestion2_3(trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d29d98c5-6939-446a-bfeb-a751d10cddf6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5eb57ec7-7646-412f-938f-e014c315599f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Question 4 \n",
    "\n",
    "Load the PEFT model using pre-defined LoRA configs and foundation model. We set `is_trainable=False` to avoid further training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "64ddfcf6-a47c-4f9c-8da9-9f826b89e806",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "time_now = time.time()\n",
    "\n",
    "username = spark.sql(\"SELECT CURRENT_USER\").first()[0]\n",
    "peft_model_path = os.path.join(output_directory, f\"peft_model_{time_now}\")\n",
    "\n",
    "trainer.model.save_pretrained(peft_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1fb9aec2-8bc7-4d2c-84e9-fb470f70405c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mHFValidationError\u001B[0m                         Traceback (most recent call last)\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-a347761d-a8f8-4a4f-9cad-0ad575e6c1fb/lib/python3.10/site-packages/peft/utils/config.py:177\u001B[0m, in \u001B[0;36mPeftConfigMixin._get_peft_type\u001B[0;34m(cls, model_id, **hf_hub_download_kwargs)\u001B[0m\n",
       "\u001B[1;32m    176\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[0;32m--> 177\u001B[0m     config_file \u001B[38;5;241m=\u001B[39m \u001B[43mhf_hub_download\u001B[49m\u001B[43m(\u001B[49m\n",
       "\u001B[1;32m    178\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel_id\u001B[49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m    179\u001B[0m \u001B[43m        \u001B[49m\u001B[43mCONFIG_NAME\u001B[49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m    180\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mhf_hub_download_kwargs\u001B[49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m    181\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    182\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:110\u001B[0m, in \u001B[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m    109\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m arg_name \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrepo_id\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfrom_id\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mto_id\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n",
       "\u001B[0;32m--> 110\u001B[0m     \u001B[43mvalidate_repo_id\u001B[49m\u001B[43m(\u001B[49m\u001B[43marg_value\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    112\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m arg_name \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtoken\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m arg_value \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:158\u001B[0m, in \u001B[0;36mvalidate_repo_id\u001B[0;34m(repo_id)\u001B[0m\n",
       "\u001B[1;32m    157\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m repo_id\u001B[38;5;241m.\u001B[39mcount(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n",
       "\u001B[0;32m--> 158\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m HFValidationError(\n",
       "\u001B[1;32m    159\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRepo id must be in the form \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrepo_name\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m or \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnamespace/repo_name\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m:\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m    160\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mrepo_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m. Use `repo_type` argument if needed.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m    161\u001B[0m     )\n",
       "\u001B[1;32m    163\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m REPO_ID_REGEX\u001B[38;5;241m.\u001B[39mmatch(repo_id):\n",
       "\n",
       "\u001B[0;31mHFValidationError\u001B[0m: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/dbfs/mnt/dbacademy-users/labuser5526367@vocareum.com/llm-foundation-models/peft_lab_outputs/peft_model_1711384555.2843702'. Use `repo_type` argument if needed.\n",
       "\n",
       "During handling of the above exception, another exception occurred:\n",
       "\n",
       "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-881630426830408>:4\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# TODO\u001B[39;00m\n",
       "\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpeft\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m PeftModel, PeftConfig\n",
       "\u001B[0;32m----> 4\u001B[0m loaded_model \u001B[38;5;241m=\u001B[39m PeftModel\u001B[38;5;241m.\u001B[39mfrom_pretrained(foundation_model, \n",
       "\u001B[1;32m      5\u001B[0m                                         peft_model_path, \n",
       "\u001B[1;32m      6\u001B[0m                                         is_trainable\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-a347761d-a8f8-4a4f-9cad-0ad575e6c1fb/lib/python3.10/site-packages/peft/peft_model.py:244\u001B[0m, in \u001B[0;36mPeftModel.from_pretrained\u001B[0;34m(cls, model, model_id, adapter_name, is_trainable, config, **kwargs)\u001B[0m\n",
       "\u001B[1;32m    241\u001B[0m \u001B[38;5;66;03m# load the config\u001B[39;00m\n",
       "\u001B[1;32m    242\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m config \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
       "\u001B[1;32m    243\u001B[0m     config \u001B[38;5;241m=\u001B[39m PEFT_TYPE_TO_CONFIG_MAPPING[\n",
       "\u001B[0;32m--> 244\u001B[0m         \u001B[43mPeftConfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_peft_type\u001B[49m\u001B[43m(\u001B[49m\n",
       "\u001B[1;32m    245\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmodel_id\u001B[49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m    246\u001B[0m \u001B[43m            \u001B[49m\u001B[43msubfolder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43msubfolder\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m    247\u001B[0m \u001B[43m            \u001B[49m\u001B[43mrevision\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrevision\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m    248\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcache_dir\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m    249\u001B[0m \u001B[43m            \u001B[49m\u001B[43muse_auth_token\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43muse_auth_token\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m    250\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    251\u001B[0m     ]\u001B[38;5;241m.\u001B[39mfrom_pretrained(model_id, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
       "\u001B[1;32m    252\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(config, PeftConfig):\n",
       "\u001B[1;32m    253\u001B[0m     config\u001B[38;5;241m.\u001B[39minference_mode \u001B[38;5;241m=\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m is_trainable\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-a347761d-a8f8-4a4f-9cad-0ad575e6c1fb/lib/python3.10/site-packages/peft/utils/config.py:183\u001B[0m, in \u001B[0;36mPeftConfigMixin._get_peft_type\u001B[0;34m(cls, model_id, **hf_hub_download_kwargs)\u001B[0m\n",
       "\u001B[1;32m    177\u001B[0m         config_file \u001B[38;5;241m=\u001B[39m hf_hub_download(\n",
       "\u001B[1;32m    178\u001B[0m             model_id,\n",
       "\u001B[1;32m    179\u001B[0m             CONFIG_NAME,\n",
       "\u001B[1;32m    180\u001B[0m             \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mhf_hub_download_kwargs,\n",
       "\u001B[1;32m    181\u001B[0m         )\n",
       "\u001B[1;32m    182\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n",
       "\u001B[0;32m--> 183\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCan\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt find \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mCONFIG_NAME\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m at \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\u001B[1;32m    185\u001B[0m loaded_attributes \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39mfrom_json_file(config_file)\n",
       "\u001B[1;32m    186\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m loaded_attributes[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpeft_type\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
       "\n",
       "\u001B[0;31mValueError\u001B[0m: Can't find 'adapter_config.json' at '/dbfs/mnt/dbacademy-users/labuser5526367@vocareum.com/llm-foundation-models/peft_lab_outputs/peft_model_1711384555.2843702'"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mHFValidationError\u001B[0m                         Traceback (most recent call last)\nFile \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-a347761d-a8f8-4a4f-9cad-0ad575e6c1fb/lib/python3.10/site-packages/peft/utils/config.py:177\u001B[0m, in \u001B[0;36mPeftConfigMixin._get_peft_type\u001B[0;34m(cls, model_id, **hf_hub_download_kwargs)\u001B[0m\n\u001B[1;32m    176\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 177\u001B[0m     config_file \u001B[38;5;241m=\u001B[39m \u001B[43mhf_hub_download\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    178\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    179\u001B[0m \u001B[43m        \u001B[49m\u001B[43mCONFIG_NAME\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    180\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mhf_hub_download_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    181\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    182\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\nFile \u001B[0;32m/databricks/python/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:110\u001B[0m, in \u001B[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    109\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m arg_name \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrepo_id\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfrom_id\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mto_id\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n\u001B[0;32m--> 110\u001B[0m     \u001B[43mvalidate_repo_id\u001B[49m\u001B[43m(\u001B[49m\u001B[43marg_value\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    112\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m arg_name \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtoken\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m arg_value \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\nFile \u001B[0;32m/databricks/python/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:158\u001B[0m, in \u001B[0;36mvalidate_repo_id\u001B[0;34m(repo_id)\u001B[0m\n\u001B[1;32m    157\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m repo_id\u001B[38;5;241m.\u001B[39mcount(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m--> 158\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m HFValidationError(\n\u001B[1;32m    159\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRepo id must be in the form \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrepo_name\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m or \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnamespace/repo_name\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m:\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    160\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mrepo_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m. Use `repo_type` argument if needed.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    161\u001B[0m     )\n\u001B[1;32m    163\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m REPO_ID_REGEX\u001B[38;5;241m.\u001B[39mmatch(repo_id):\n\n\u001B[0;31mHFValidationError\u001B[0m: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/dbfs/mnt/dbacademy-users/labuser5526367@vocareum.com/llm-foundation-models/peft_lab_outputs/peft_model_1711384555.2843702'. Use `repo_type` argument if needed.\n\nDuring handling of the above exception, another exception occurred:\n\n\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)\nFile \u001B[0;32m<command-881630426830408>:4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# TODO\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpeft\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m PeftModel, PeftConfig\n\u001B[0;32m----> 4\u001B[0m loaded_model \u001B[38;5;241m=\u001B[39m PeftModel\u001B[38;5;241m.\u001B[39mfrom_pretrained(foundation_model, \n\u001B[1;32m      5\u001B[0m                                         peft_model_path, \n\u001B[1;32m      6\u001B[0m                                         is_trainable\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\nFile \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-a347761d-a8f8-4a4f-9cad-0ad575e6c1fb/lib/python3.10/site-packages/peft/peft_model.py:244\u001B[0m, in \u001B[0;36mPeftModel.from_pretrained\u001B[0;34m(cls, model, model_id, adapter_name, is_trainable, config, **kwargs)\u001B[0m\n\u001B[1;32m    241\u001B[0m \u001B[38;5;66;03m# load the config\u001B[39;00m\n\u001B[1;32m    242\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m config \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    243\u001B[0m     config \u001B[38;5;241m=\u001B[39m PEFT_TYPE_TO_CONFIG_MAPPING[\n\u001B[0;32m--> 244\u001B[0m         \u001B[43mPeftConfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_peft_type\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    245\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmodel_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    246\u001B[0m \u001B[43m            \u001B[49m\u001B[43msubfolder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43msubfolder\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    247\u001B[0m \u001B[43m            \u001B[49m\u001B[43mrevision\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrevision\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    248\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcache_dir\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    249\u001B[0m \u001B[43m            \u001B[49m\u001B[43muse_auth_token\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43muse_auth_token\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    250\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    251\u001B[0m     ]\u001B[38;5;241m.\u001B[39mfrom_pretrained(model_id, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    252\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(config, PeftConfig):\n\u001B[1;32m    253\u001B[0m     config\u001B[38;5;241m.\u001B[39minference_mode \u001B[38;5;241m=\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m is_trainable\n\nFile \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-a347761d-a8f8-4a4f-9cad-0ad575e6c1fb/lib/python3.10/site-packages/peft/utils/config.py:183\u001B[0m, in \u001B[0;36mPeftConfigMixin._get_peft_type\u001B[0;34m(cls, model_id, **hf_hub_download_kwargs)\u001B[0m\n\u001B[1;32m    177\u001B[0m         config_file \u001B[38;5;241m=\u001B[39m hf_hub_download(\n\u001B[1;32m    178\u001B[0m             model_id,\n\u001B[1;32m    179\u001B[0m             CONFIG_NAME,\n\u001B[1;32m    180\u001B[0m             \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mhf_hub_download_kwargs,\n\u001B[1;32m    181\u001B[0m         )\n\u001B[1;32m    182\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[0;32m--> 183\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCan\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt find \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mCONFIG_NAME\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m at \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    185\u001B[0m loaded_attributes \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39mfrom_json_file(config_file)\n\u001B[1;32m    186\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m loaded_attributes[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpeft_type\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\n\u001B[0;31mValueError\u001B[0m: Can't find 'adapter_config.json' at '/dbfs/mnt/dbacademy-users/labuser5526367@vocareum.com/llm-foundation-models/peft_lab_outputs/peft_model_1711384555.2843702'",
       "errorSummary": "<span class='ansi-red-fg'>ValueError</span>: Can't find 'adapter_config.json' at '/dbfs/mnt/dbacademy-users/labuser5526367@vocareum.com/llm-foundation-models/peft_lab_outputs/peft_model_1711384555.2843702'",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO\n",
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "loaded_model = PeftModel.from_pretrained(foundation_model, \n",
    "                                        peft_model_path, \n",
    "                                        is_trainable=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "09550a3d-3833-4108-b75b-c493cbf6af39",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-881630426830409>:3\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Test your answer. DO NOT MODIFY THIS CELL.\u001B[39;00m\n",
       "\u001B[0;32m----> 3\u001B[0m dbTestQuestion2_4(\u001B[43mloaded_model\u001B[49m)\n",
       "\n",
       "\u001B[0;31mNameError\u001B[0m: name 'loaded_model' is not defined"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\nFile \u001B[0;32m<command-881630426830409>:3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Test your answer. DO NOT MODIFY THIS CELL.\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m dbTestQuestion2_4(\u001B[43mloaded_model\u001B[49m)\n\n\u001B[0;31mNameError\u001B[0m: name 'loaded_model' is not defined",
       "errorSummary": "<span class='ansi-red-fg'>NameError</span>: name 'loaded_model' is not defined",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test your answer. DO NOT MODIFY THIS CELL.\n",
    "\n",
    "dbTestQuestion2_4(loaded_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c7a0fd45-fd06-4e5b-8554-7e70e6bdfaa6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8055e5e3-a735-4e40-8146-6cc1d623c01e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Question 5\n",
    "\n",
    "Generate output tokens to the same input we provided in the demo notebook before. How do the outputs compare?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a8e804b-3744-4af9-8b5b-d560d0b35949",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Two things are infinite: ““““““““““']\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "# inputs = tokenizer(\"Two things are infinite: \", return_tensors=\"pt\")\n",
    "# outputs = peft_model.generate(\n",
    "#     input_ids=<FILL_IN>, \n",
    "#     attention_mask=<FILL_IN>, \n",
    "#     max_new_tokens=<FILL_IN>, \n",
    "#     eos_token_id=tokenizer.eos_token_id\n",
    "#     )\n",
    "# print(tokenizer.batch_decode(<FILL_IN>, skip_special_tokens=True))\n",
    "\n",
    "inputs = tokenizer(\"Two things are infinite: \", return_tensors=\"pt\")\n",
    "outputs = peft_model.generate(\n",
    "    input_ids=inputs[\"input_ids\"], \n",
    "    attention_mask=inputs[\"attention_mask\"],\n",
    "    max_new_tokens=10,\n",
    "    eos_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "print(tokenizer.batch_decode(outputs, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5964a276-c787-4aa6-ad2f-f2870af5f7c3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32mPASSED\u001B[0m: All tests passed for lesson2, question5\n\u001B[32mRESULTS RECORDED\u001B[0m: Click `Submit` when all questions are completed to log the results.\n"
     ]
    }
   ],
   "source": [
    "# Test your answer. DO NOT MODIFY THIS CELL.\n",
    "\n",
    "dbTestQuestion2_5(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9ebea45b-f676-425f-8c78-f4ff53a1391c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "&copy; 2023 Databricks, Inc. All rights reserved.<br/>\n",
    "Apache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"https://www.apache.org/\">Apache Software Foundation</a>.<br/>\n",
    "<br/>\n",
    "<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"https://help.databricks.com/\">Support</a>"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "LLM 02L - LoRA with PEFT",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
